{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "\n",
    "import dendro\n",
    "import exif\n",
    "\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn import metrics\n",
    "\n",
    "directory = \"../data\"\n",
    "\n",
    "\n",
    "max_pce = 60.0\n",
    "max_ncc = 0.02\n",
    "\n",
    "\n",
    "def plot_distance_matrices(matrix1, matrix2, matrix3, matrix4):\n",
    "    f, ((ax1, ax2), (ax3, ax4)) = pyplot.subplots(nrows=2, ncols=2, sharex=True, sharey=True)\n",
    "    ax1.set_adjustable('box-forced')\n",
    "    ax2.set_adjustable('box-forced')\n",
    "    ax3.set_adjustable('box-forced')\n",
    "    ax4.set_adjustable('box-forced')\n",
    "\n",
    "    vmax = matrix1.max()\n",
    "    ax1.imshow(matrix1, vmin=0.0, vmax=vmax)\n",
    "    ax1.set_title(\"NCC distance\")\n",
    "    ax2.imshow(matrix2, vmin=0.0, vmax=vmax)\n",
    "    ax2.set_title(\"PCE distance\")\n",
    "    ax3.imshow(matrix3, vmin=0.0, vmax=vmax)\n",
    "    ax3.set_title(\"PCE0 distance\")\n",
    "    ax4.imshow(matrix4, vmin=0.0, vmax=vmax)\n",
    "    ax4.set_title(\"Ground truth\")\n",
    "\n",
    "    size = matrix3.shape[0]\n",
    "    def hover_func(x, y):\n",
    "        x = int(x+1)\n",
    "        y = int(y+1)\n",
    "        if y >= size:\n",
    "            y = size-1\n",
    "        if x >= size:\n",
    "            x = size-1\n",
    "        return str(x) + \",\" + str(y) + \" \" + str(matrix1[y,x]) + \" \" + str(matrix2[y,x]) + \" \"+ str(matrix3[y,x])\n",
    "\n",
    "    ax1.format_coord = hover_func\n",
    "    ax2.format_coord = hover_func\n",
    "    ax3.format_coord = hover_func\n",
    "    ax4.format_coord = hover_func\n",
    "    f.set_size_inches(10, 10, forward=True)\n",
    "    f.tight_layout()\n",
    "    pyplot.show()\n",
    "    input()\n",
    "\n",
    "#function to rename the labels from the found clustering to the labels in the true clustering\n",
    "#not very useful but may come in handy at some point\n",
    "def rename_clusters(clustering, true_clustering):\n",
    "    clustering = numpy.array(clustering)\n",
    "    #initialize new labels as -1\n",
    "    labels = numpy.zeros(clustering.shape, dtype=numpy.int) -1\n",
    "    true_clustering = numpy.array(true_clustering)\n",
    "    clusters = set(clustering)\n",
    "    #for each cluster that we found\n",
    "    for c in clusters:\n",
    "        #get the ids of the clusters its values really belong to\n",
    "        true_ids = true_clustering[clustering == c]\n",
    "        if len(true_ids) > 0:\n",
    "            id = int(numpy.median(true_ids))\n",
    "            #using all 80% match here\n",
    "            #could use most common value or something\n",
    "            matches = list(true_ids).count(id)\n",
    "            if matches > 0.8*len(true_ids):\n",
    "                labels[clustering == c] = id\n",
    "            #else:\n",
    "            #    print \"problem at c=\", c, \"id=\", id, \"true_ids=\", true_ids\n",
    "\n",
    "    #do something with clusters that we could not assign a new name\n",
    "    for i in range(len(clustering)):\n",
    "        if labels[i] == -1:\n",
    "            labels[i] = 9 #assign arbitrary cluster id, lumping everything we could not match into a 'rest' cluster\n",
    "\n",
    "    return labels\n",
    "\n",
    "def map_ncc_scores_to_pce_domain(matrix_pce, matrix_ncc):\n",
    "    #map the ncc values into the range of pce values and shift to align medians\n",
    "    matrix_ncc = matrix_ncc * (max_pce/max_ncc)\n",
    "    diff = numpy.median(matrix_pce) - numpy.median(matrix_ncc)      #median works a bit better\n",
    "    #diff = numpy.average(matrix_pce) - numpy.average(matrix_ncc)\n",
    "    matrix_ncc += diff\n",
    "    matrix_ncc[matrix_ncc < 0.0] = 0.0\n",
    "\n",
    "    return matrix_pce, matrix_ncc\n",
    "\n",
    "def convert_similarity_to_distance(matrix):\n",
    "    #cut off too high values, the idea is that if it exceeds this threshold it is a hit anyway\n",
    "    matrix[matrix > max_pce] = max_pce\n",
    "    matrix[matrix < 0.0] = 0.0\n",
    "\n",
    "    #prevent div by zero\n",
    "    matrix += 0.0000001\n",
    "\n",
    "    #convert similarity score to distance, tried various options\n",
    "    matrix = max_pce / matrix                 #best for the moment\n",
    "    #matrix = 200 - matrix\n",
    "    #matrix = numpy.sqrt(max_pce - matrix)\n",
    "    #matrix = - numpy.log(matrix/max_pce)     #sort of okay, also had FP\n",
    "\n",
    "    #set maximum distance at max_pce\n",
    "    matrix[matrix > max_pce] = max_pce\n",
    "\n",
    "    #reshape to square matrix form\n",
    "    numfiles = int(numpy.sqrt(matrix.size))\n",
    "    matrix = matrix.reshape(numfiles, numfiles)\n",
    "\n",
    "    #zero diagonal\n",
    "    index = list(range(numfiles))\n",
    "    matrix[index, index] = 0.0\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def combine_pce_and_ncc_distances(matrix_pce, matrix_ncc):\n",
    "    #experiment with methods for combining the distance matrices into one\n",
    "    matrix = numpy.minimum(matrix_pce, matrix_ncc)  #minimum distance\n",
    "    #matrix = numpy.sqrt(matrix_pce * matrix_ncc)   #geometric mean\n",
    "    #matrix = (matrix_pce + matrix_ncc) / 2.0       #arithmetic mean\n",
    "\n",
    "    #print \"pce median max\", numpy.median(matrix_pce), matrix_pce.max()\n",
    "    #print \"ncc median max\", numpy.median(matrix_ncc), matrix_ncc.max()\n",
    "    return matrix\n",
    "\n",
    "def print_metrics(true_clustering, cluster):\n",
    "    #try some metrics from sklearn\n",
    "    print(\"\\n\")\n",
    "    print(\"adjusted rand score [-1.0 (bad) to 1.0 (good)]\\n\", metrics.adjusted_rand_score(true_clustering, cluster))\n",
    "    print(\"mutual information based score [0.0 (bad) to 1.0 (good)]\\n\", metrics.adjusted_mutual_info_score(true_clustering, cluster))\n",
    "    print(\"homogeneity, completeness, v measure [0.0 (bad) to 1.0 (good)]\\n\", metrics.homogeneity_completeness_v_measure(true_clustering, cluster))\n",
    "\n",
    "\n",
    "def get_ground_truth():\n",
    "    filelist = numpy.loadtxt(directory + \"/filelist.txt\", dtype=numpy.string_)\n",
    "    numfiles = filelist.size\n",
    "    matrix_ans = numpy.zeros([numfiles,numfiles], dtype=numpy.float)\n",
    "    for i in range(numfiles):\n",
    "        for j in range(numfiles):\n",
    "            cam1 = \"_\".join(filelist[i].split(\"_\")[:-1])\n",
    "            cam2 = \"_\".join(filelist[j].split(\"_\")[:-1])\n",
    "            if cam1 == cam2:\n",
    "                matrix_ans[i][j] = 1.0\n",
    "            else:\n",
    "                matrix_ans[i][j] = 100.0\n",
    "            if i == j:\n",
    "                matrix_ans[i][j] = 0.0\n",
    "    return matrix_ans\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "\n",
    "#    import sys\n",
    "#    if len(sys.argv) != 2:\n",
    "#        print(\"Usage: ./camera_identification <name-of-dataset>\")\n",
    "#        exit()\n",
    "#    import os\n",
    "#    if not os.path.isdir(directory + \"/\" + sys.argv[1]):\n",
    "#        print(\"incorrect dataset name, cannot find \" + directory + \"/\" + sys.argv[1])\n",
    "#        exit()\n",
    "\n",
    "    dataset =\"pentax\" #sys.argv[1]\n",
    "    directory = directory + \"/\" + dataset\n",
    "\n",
    "    #load the distance matrixes from files\n",
    "    matrix_pce = numpy.fromfile(directory + \"/matrix-\" + dataset + \"-pce.dat\", dtype='>d')\n",
    "    matrix_pce0 = numpy.fromfile(directory + \"/matrix-\" + dataset + \"-pce0.dat\", dtype='>d')\n",
    "    matrix_ncc = numpy.fromfile(directory + \"/matrix-\" + dataset + \"-ncc.dat\", dtype='>d')\n",
    "\n",
    "    matrix_pce, matrix_ncc = map_ncc_scores_to_pce_domain(matrix_pce, matrix_ncc)\n",
    "    matrix_ncc = convert_similarity_to_distance(matrix_ncc)\n",
    "    matrix_pce = convert_similarity_to_distance(matrix_pce)\n",
    "    matrix_pce0 = convert_similarity_to_distance(matrix_pce0)\n",
    "\n",
    "    matrix_ans = get_ground_truth()\n",
    "    plot_distance_matrices(matrix_ncc, matrix_pce, matrix_pce0, matrix_ans)\n",
    "\n",
    "\n",
    "    #set metric to use for clustering\n",
    "    matrix = matrix_pce\n",
    "\n",
    "\n",
    "    #hierarchical clustering part starts here\n",
    "    linkage = dendro.compute_linkage(matrix)\n",
    "\n",
    "    #methods = ['single', 'complete', 'average', 'weighted', 'centroid', 'median', 'ward']\n",
    "    #for method in methods:\n",
    "    #    linkage = sch.linkage(matrix, method=method)\n",
    "\n",
    "\n",
    "    threshold = 0.7*linkage[:,2].max() # default threshold used in sch.dendogram is 0.7*linkage[:,2].max()\n",
    "\n",
    "\n",
    "    #dendrogram = dendro.compute_dendrogram(linkage)\n",
    "    dendrogram = dendro.plot_dendrogram_and_matrix(linkage, matrix, color_threshold=threshold)\n",
    "\n",
    "\n",
    "    #compute flat clustering in the exact same way as sch.dendogram colors the clusters\n",
    "    cluster = numpy.array(sch.fcluster(linkage, threshold, criterion='distance'), dtype=numpy.int)\n",
    "    numpy.set_printoptions(threshold=numpy.nan) # make numpy print the full array\n",
    "    print(\"flat clustering:\\n\", cluster)\n",
    "\n",
    "    #get the actual clustering\n",
    "    filelist = numpy.loadtxt(directory + \"/filelist.txt\", dtype=numpy.string_)\n",
    "    true_clustering = [\"_\".join(s.split(\"_\")[:-1]) for s in filelist]\n",
    "    true_clusters = sorted(set(true_clustering))\n",
    "    true_labels = numpy.array([true_clusters.index(id) for id in true_clustering], dtype=numpy.int)\n",
    "    print(\"true clustering:\\n\", true_labels)\n",
    "\n",
    "\n",
    "    print_metrics(true_labels, cluster)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #go interactive\n",
    "    #import readline\n",
    "    #import rlcompleter\n",
    "    #readline.parse_and_bind(\"tab: complete\")\n",
    "    #import code\n",
    "    #code.interact(local=dict(globals(), **locals()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
