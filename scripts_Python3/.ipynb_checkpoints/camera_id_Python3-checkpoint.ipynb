{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import math\n",
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "\n",
    "import dendro\n",
    "import exif\n",
    "\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn import metrics\n",
    "\n",
    "directory = \"../data\"\n",
    "\n",
    "\n",
    "max_pce = 60.0\n",
    "max_ncc = 0.02\n",
    "\n",
    "def draw(arraytje):\n",
    "    pyplot.hist(arraytje, bins =100)\n",
    "    \n",
    "#all transformations of similarity are monotonic (very important!)\n",
    "\n",
    "# this transformation streches non-linearly the distances, such that the small distances fall into\n",
    "# (0,50) and the large into (0,100). \n",
    "def transform1(x):# hardcoded things need to be replaced by critical points (automated) when possible. To be done by Sonja   \n",
    "    if x > 0:\n",
    "        x = math.log(x)\n",
    "    else:\n",
    "        x = 100000 # the diagonal should have the largest values, not 0\n",
    "        x = math.log(x)\n",
    "    minx = -22.3000\n",
    "    maxx = 11.4900\n",
    "    x = (x-minx)/(maxx-minx)\n",
    "    if x<0.4:\n",
    "        x=0.4\n",
    "    if x >0.9:\n",
    "        x=0.9\n",
    "    \n",
    "    if x < 0.76:\n",
    "        a = 1/0.36\n",
    "        b = -a*0.4\n",
    "    else:\n",
    "        a = 0.414/0.14\n",
    "        b = 1-a*0.76\n",
    "    x = a*x + b        \n",
    "    x = math.pow(x,2)\n",
    "    maxx = 2 # for x^2\n",
    "    x = x/maxx\n",
    "    x= 1-x # convert from similarity to distance\n",
    "    x=x*100#used to be 80. but in the ground  truth the values are 0-100\n",
    "    return x   \n",
    "\n",
    "# this transformation streches non-linearly the distances but emphasizes the large distances\n",
    "def transform(x):# hardcoded things need to be replaced by critical points (automated) when possible. To be done by Sonja   \n",
    "    if x > 0:\n",
    "        x = math.log(x)\n",
    "    else:\n",
    "        x = 100000 # the diagonal should have the largest values, not 0\n",
    "        x = math.log(x)\n",
    "    minx = -22.3000\n",
    "    maxx = 11.4900\n",
    "    x = (x-minx)/(maxx-minx)\n",
    "    if x<0.4:\n",
    "        x=0.4\n",
    "    if x >0.9:\n",
    "        x=0.9\n",
    "    x = x/0.36 - 0.4/0.36    \n",
    "    x = math.pow(x,3)\n",
    "    maxx = 2.6791838135\n",
    "    x = x/maxx\n",
    "    x= 1-x # convert from similarity to distance\n",
    "    x=x*100# the ground  truth the values are 0 to 100\n",
    "    return x  \n",
    "\n",
    "#this one again emphasizes the large distances\n",
    "def transform_orig(x):# hardcoded things need to be replaced by critical points (automated) when possible. To be done by Sonja   \n",
    "    if x > 0:\n",
    "        x = math.log(x)\n",
    "    else:\n",
    "        x = 100000 # the diagonal should have the largest values, not 0\n",
    "        x = math.log(x)\n",
    "    minx = -22.3000\n",
    "    maxx = 11.4900\n",
    "    x = (x-minx)/(maxx-minx)\n",
    "    if x<0.4:\n",
    "        x=0.4\n",
    "    if x >0.9:\n",
    "        x=0.9\n",
    "    x = x/0.335 - 0.4/0.335    \n",
    "    x = math.pow(x,3)\n",
    "    maxx = 3.3248770627 # for x^3\n",
    "    x = x/maxx\n",
    "    x= 1-x # convert from similarity to distance\n",
    "    x=x*100\n",
    "    return x   \n",
    "\n",
    "\n",
    "def plot_distance_matrices(matrix1, matrix2, matrix3, matrix4):\n",
    "    f, ((ax1, ax2), (ax3, ax4)) = pyplot.subplots(nrows=2, ncols=2, sharex=True, sharey=True)\n",
    "    ax1.set_adjustable('box-forced')\n",
    "    ax2.set_adjustable('box-forced')\n",
    "    ax3.set_adjustable('box-forced')\n",
    "    ax4.set_adjustable('box-forced')\n",
    "\n",
    "    vmax = matrix1.max()\n",
    "    ax1.imshow(matrix1, vmin=0.0, vmax=vmax)\n",
    "    ax1.set_title(\"NCC distance\")\n",
    "    ax2.imshow(matrix2, vmin=0.0, vmax=vmax)\n",
    "    ax2.set_title(\"PCE distance\")\n",
    "    ax3.imshow(matrix3, vmin=0.0, vmax=vmax)\n",
    "    ax3.set_title(\"PCE0 distance\")\n",
    "    ax4.imshow(matrix4, vmin=0.0, vmax=vmax)\n",
    "    ax4.set_title(\"Ground truth\")\n",
    "\n",
    "    size = matrix3.shape[0]\n",
    "    def hover_func(x, y):\n",
    "        x = int(x+1)\n",
    "        y = int(y+1)\n",
    "        if y >= size:\n",
    "            y = size-1\n",
    "        if x >= size:\n",
    "            x = size-1\n",
    "        return str(x) + \",\" + str(y) + \" \" + str(matrix1[y,x]) + \" \" + str(matrix2[y,x]) + \" \"+ str(matrix3[y,x])\n",
    "\n",
    "    ax1.format_coord = hover_func\n",
    "    ax2.format_coord = hover_func\n",
    "    ax3.format_coord = hover_func\n",
    "    ax4.format_coord = hover_func\n",
    "    f.set_size_inches(10, 10, forward=True)\n",
    "    f.tight_layout()\n",
    "    pyplot.show()\n",
    "    #raw_input()\n",
    "\n",
    "#function to rename the labels from the found clustering to the labels in the true clustering\n",
    "#not very useful but may come in handy at some point\n",
    "def rename_clusters(clustering, true_clustering):\n",
    "    clustering = numpy.array(clustering)\n",
    "    #initialize new labels as -1\n",
    "    labels = numpy.zeros(clustering.shape, dtype=numpy.int) -1\n",
    "    true_clustering = numpy.array(true_clustering)\n",
    "    clusters = set(clustering)\n",
    "    #for each cluster that we found\n",
    "    for c in clusters:\n",
    "        #get the ids of the clusters its values really belong to\n",
    "        true_ids = true_clustering[clustering == c]\n",
    "        if len(true_ids) > 0:\n",
    "            id = int(numpy.median(true_ids))\n",
    "            #using all 80% match here\n",
    "            #could use most common value or something\n",
    "            matches = list(true_ids).count(id)\n",
    "            if matches > 0.8*len(true_ids):\n",
    "                labels[clustering == c] = id\n",
    "            #else:\n",
    "            #    print \"problem at c=\", c, \"id=\", id, \"true_ids=\", true_ids\n",
    "\n",
    "    #do something with clusters that we could not assign a new name\n",
    "    for i in range(len(clustering)):\n",
    "        if labels[i] == -1:\n",
    "            labels[i] = 9 #assign arbitrary cluster id, lumping everything we could not match into a 'rest' cluster\n",
    "\n",
    "    return labels\n",
    "\n",
    "def map_ncc_scores_to_pce_domain(matrix_pce, matrix_ncc):\n",
    "    #map the ncc values into the range of pce values and shift to align medians\n",
    "    matrix_ncc = matrix_ncc * (max_pce/max_ncc)\n",
    "    diff = numpy.median(matrix_pce) - numpy.median(matrix_ncc)      #median works a bit better\n",
    "    #diff = numpy.average(matrix_pce) - numpy.average(matrix_ncc)\n",
    "    matrix_ncc += diff\n",
    "    matrix_ncc[matrix_ncc < 0.0] = 0.0\n",
    "\n",
    "    return matrix_pce, matrix_ncc\n",
    "\n",
    "def convert_similarity_to_distance(matrix):# needs to be cleaned and optimized for time\n",
    "    print(\"length of matrix = \"  + str(len(matrix)))\n",
    "    i=0\n",
    "    for element in matrix:\n",
    "        matrix[i] = transform(element)        \n",
    "        i+=1    \n",
    "\n",
    "    #reshape to square matrix form\n",
    "    numfiles = int(numpy.sqrt(matrix.size))\n",
    "    matrix = matrix.reshape(numfiles, numfiles)\n",
    "\n",
    "    #zero diagonal\n",
    "    index = range(numfiles)\n",
    "    matrix[index, index] = 0.0\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def convert_similarity_to_distance2(matrix):#the original by Ben\n",
    "    #cut off too high values, the idea is that if it exceeds this threshold it is a hit anyway\n",
    "    matrix[matrix > max_pce] = max_pce\n",
    "    matrix[matrix < 0.0] = 0.0\n",
    "\n",
    "    #prevent div by zero\n",
    "    matrix += 0.0000001\n",
    "\n",
    "    #convert similarity score to distance, tried various options\n",
    "    matrix = max_pce / matrix                 #best for the moment\n",
    "    #matrix = 200 - matrix\n",
    "    #matrix = numpy.sqrt(max_pce - matrix)\n",
    "    #matrix = - numpy.log(matrix/max_pce)     #sort of okay, also had FP\n",
    "\n",
    "    #set maximum distance at max_pce\n",
    "    matrix[matrix > max_pce] = max_pce\n",
    "\n",
    "    #reshape to square matrix form\n",
    "    numfiles = int(numpy.sqrt(matrix.size))\n",
    "    matrix = matrix.reshape(numfiles, numfiles)\n",
    "\n",
    "    #zero diagonal\n",
    "    index = range(numfiles)\n",
    "    matrix[index, index] = 0.0\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def combine_pce_and_ncc_distances(matrix_pce, matrix_ncc):\n",
    "    #experiment with methods for combining the distance matrices into one\n",
    "    matrix = numpy.minimum(matrix_pce, matrix_ncc)  #minimum distance\n",
    "    #matrix = numpy.sqrt(matrix_pce * matrix_ncc)   #geometric mean\n",
    "    #matrix = (matrix_pce + matrix_ncc) / 2.0       #arithmetic mean\n",
    "\n",
    "    #print \"pce median max\", numpy.median(matrix_pce), matrix_pce.max()\n",
    "    #print \"ncc median max\", numpy.median(matrix_ncc), matrix_ncc.max()\n",
    "    return matrix\n",
    "\n",
    "def print_metrics(true_clustering, cluster):\n",
    "    #try some metrics from sklearn\n",
    "    print (\"\\n\")\n",
    "    print (\"adjusted rand score [-1.0 (bad) to 1.0 (good)]\\n\", metrics.adjusted_rand_score(true_clustering, cluster))\n",
    "    print (\"mutual information based score [0.0 (bad) to 1.0 (good)]\\n\", metrics.adjusted_mutual_info_score(true_clustering, cluster))\n",
    "    #print (\"homogeneity, completeness, v measure [0.0 (bad) to 1.0 (good)]\\n\", metrics.homogeneity_completeness_v_measure(true_clustering, cluster)\n",
    "\n",
    "\n",
    "def get_ground_truth():\n",
    "    filelist = numpy.loadtxt(directory + \"/filelist.txt\", dtype=numpy.string_)\n",
    "    numfiles = filelist.size    \n",
    "    matrix_ans = numpy.zeros([numfiles,numfiles], dtype=numpy.float)\n",
    "    for i in range(numfiles):\n",
    "        for j in range(numfiles):          \n",
    "            cam1 = str(filelist[i]).split(\"_\")[:-1]\n",
    "            cam2 = str(filelist[j]).split(\"_\")[:-1]\n",
    "            if cam1 == cam2:\n",
    "                matrix_ans[i][j] = 1.0\n",
    "            else:\n",
    "                matrix_ans[i][j] = 100.0\n",
    "            if i == j:\n",
    "                matrix_ans[i][j] = 0.0\n",
    "    return matrix_ans\n",
    "\n",
    "\n",
    "if True:\n",
    "\n",
    "    dataset = \"pentax\" #.argv[1]\n",
    "    directory = directory + \"/\" + dataset\n",
    "\n",
    "    #load the distance matrixes from files\n",
    "    matrix_pce = numpy.fromfile(directory + \"/matrix-\" + dataset + \"-pce.dat\", dtype='>d')\n",
    "    matrix_pce0 = numpy.fromfile(directory + \"/matrix-\" + dataset + \"-pce0.dat\", dtype='>d')\n",
    "    matrix_ncc = numpy.fromfile(directory + \"/matrix-\" + dataset + \"-ncc.dat\", dtype='>d')\n",
    "\n",
    "    matrix_pce, matrix_ncc = map_ncc_scores_to_pce_domain(matrix_pce, matrix_ncc)\n",
    "    matrix_ncc = convert_similarity_to_distance2(matrix_ncc)\n",
    "   \n",
    "    matrix_pce = convert_similarity_to_distance(matrix_pce)# for now only for PCE the new conversion is used\n",
    "    draw (matrix_pce)\n",
    "    print(\"max=\")\n",
    "    print(matrix_pce.max())\n",
    "    print(\"min=\")\n",
    "    print(matrix_pce.min())\n",
    "    matrix_pce0 = convert_similarity_to_distance2(matrix_pce0)\n",
    "\n",
    "    matrix_ans = get_ground_truth()    \n",
    "    \n",
    "    plot_distance_matrices(matrix_ncc, matrix_pce, matrix_pce0, matrix_ans)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#the plotting is crashing ('not responding'), I don't know why. Debugging it in an IDE did not help :(. \n",
    "if True:\n",
    "    #set metric to use for clustering\n",
    "    matrix = matrix_pce\n",
    "\n",
    "\n",
    "    #hierarchical clustering part starts here\n",
    "    linkage = dendro.compute_linkage(matrix)\n",
    "\n",
    "    #methods = ['single', 'complete', 'average', 'weighted', 'centroid', 'median', 'ward']\n",
    "    #for method in methods:\n",
    "    #    linkage = sch.linkage(matrix, method=method)\n",
    "\n",
    "\n",
    "    threshold = 0.7*linkage[:,2].max() # default threshold used in sch.dendogram is 0.7*linkage[:,2].max()\n",
    "\n",
    "\n",
    "    #dendrogram = dendro.compute_dendrogram(linkage)\n",
    "    dendrogram = dendro.plot_dendrogram_and_matrix(linkage, matrix, color_threshold=threshold)\n",
    "\n",
    "\n",
    "    #compute flat clustering in the exact same way as sch.dendogram colors the clusters\n",
    "    cluster = numpy.array(sch.fcluster(linkage, threshold, criterion='distance'), dtype=numpy.int)\n",
    "    numpy.set_printoptions(threshold=numpy.nan) # make numpy print the full array\n",
    "    print (\"flat clustering:\\n\", cluster)\n",
    "\n",
    "    #get the actual clustering\n",
    "    filelist = numpy.loadtxt(directory + \"/filelist.txt\", dtype=numpy.string_)\n",
    "    true_clustering = [\"_\".join(str(s).split(\"_\")[:-1]) for s in filelist]\n",
    "    true_clusters = sorted(set(true_clustering))\n",
    "    true_labels = numpy.array([true_clusters.index(id) for id in true_clustering], dtype=numpy.int)\n",
    "    print (\"true clustering:\\n\", true_labels)\n",
    "\n",
    "\n",
    "    print_metrics(true_labels, cluster)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #go interactive\n",
    "    #import readline\n",
    "    #import rlcompleter\n",
    "    #readline.parse_and_bind(\"tab: complete\")\n",
    "    #import code\n",
    "    #code.interact(local=dict(globals(), **locals()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "407044-406406"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "638*637"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "math.sqrt(407044)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
